"""
Plots a line plot of the average score for each generation of AutoGrow run.

Example submit:
    python autogrow4/accessory_scripts/plot_autogrow_run.py\
        -i $PATH/Run_1/Run_0/ \
        --plot_reference_lines [['Olaparib Score',-12.8,'y'],\
            ['Niraparib',-10.7,'k'],['NAD/NADH',-10.3,'purple'],\
                ['ADP-ribose',-9.3,'maroon']]
"""
import __future__

import os
import glob
import json
import copy
import argparse
from typing import Any, Dict, List, Optional, Tuple, Union
import matplotlib  # type: ignore
from matplotlib.ticker import MaxNLocator
import matplotlib.pyplot as plt  # type: ignore
from rdkit import Chem
from rdkit.Chem.rdMolDescriptors import GetMorganFingerprint
from rdkit import DataStructs


def read_smi_file(source_file: str):
    rdkit_molecules = []
    with open(source_file) as smiles_file:
        for tsv_line in smiles_file:
            prts = tsv_line.replace("    ", "\t").strip().split("\t")
            rdkit_molecules.append(Chem.MolFromSmiles(prts[0]))

    if None in rdkit_molecules:
        raise Exception("An input molecule was not successfully read from " + source_file)

    return rdkit_molecules


def read_sdf_file(source_file: str):
    rdkit_molecules = []
    r = Chem.SDMolSupplier(source_file, sanitize=False)
    for compound in r:
        rdkit_molecules.append(compound)
    r.reset()
    return rdkit_molecules


def calc_diversity_scores(reference_comp, new_comps):
    """
    Calculate diversity scores between a reference compound and a list of new
    compounds.

    This function computes Morgan Fingerprints for each molecule and calculates
    pairwise Dice Similarity scores (1.0 meanas a perfect match, 0.0 means no
    match at all).

    Args:
        reference_comp: RDKit molecule.
        new_comps: list of RDKit molecules.

    Returns:
        List[int]: similarity values.

    Note:
        - Lower diversity scores indicate more diverse molecules.
        - Removes any None entries from the input list.
        - Uses Morgan Fingerprints with radius 10 and feature-based encoding.
    """
    similarity_values = []

    reference_comp_fp = GetMorganFingerprint(reference_comp, radius=10, useFeatures=True)
    for mol in new_comps:
        if mol is not None:
            mol_fp = GetMorganFingerprint(mol, radius=10, useFeatures=True)

            # if DiceSimilarity=1.0 its a perfect match, the smaller the
            # number the more diverse it is.
            diversity_score = DataStructs.DiceSimilarity(reference_comp_fp, mol_fp)
            similarity_values.append(diversity_score)

    return similarity_values


def get_similarity_list_per_input_comp(infolder: str, source_file: str) -> Dict[str, Union[float, str]]:
    """
    Calculate the similarity between the input compounds and the compounds generated by Autogrow.

    Args:
        infolder (str): Path to the folder containing all generation folders.
        source_file (str): Path to the input files containing the compounds.

    Returns:
        Dict[str, Union[float, str]]: Dictionary of lists of similarity values, with compound ID as keys.
    """
    similarity_dict = {}

    if ".smi" in source_file:
        input_rdkit_molecules = read_smi_file(source_file)
    elif ".sdf" in source_file:
        input_rdkit_molecules = read_sdf_file(source_file)

    ranked_file = infolder + os.sep + "summary_ranked.sdf"
    ranked_molecules = read_sdf_file(ranked_file)

    for i in range(len(input_rdkit_molecules)):
        reference_mol = input_rdkit_molecules[i]
        similarity_dict["compound_" + str(i + 1)] = calc_diversity_scores(reference_mol, ranked_molecules)

    return similarity_dict


def get_ave_similarity_per_generated_comp(infolder: str, source_file: str) -> Dict[str, Union[float, str]]:
    """
    Calculate the average similarity between the compounds generated by Autogrow and the input compounds.

    Args:
        infolder (str): Path to the folder containing all generation folders.
        source_file (str): Path to the input files containing the compounds.

    Returns:
        Dict[str, Union[float, str]]: Dictionary of average similarity values, with compound ID as keys.

    Notes:
        if a generated molecule is not successfully read, a similarity equals to 1 is assigned.
    """
    average_similarity_dict = {}

    if ".smi" in source_file:
        input_rdkit_molecules = read_smi_file(source_file)
    elif ".sdf" in source_file:
        input_rdkit_molecules = read_sdf_file(source_file)

    ranked_file = infolder + os.sep + "summary_ranked.sdf"
    ranked_molecules = read_sdf_file(ranked_file)

    for i in range(len(ranked_molecules)):
        reference_mol = ranked_molecules[i]
        if reference_mol is None:
            average_similarity_dict["compound_" + str(i + 1)] = -0.05
        else:
            similarity_values = calc_diversity_scores(reference_mol, input_rdkit_molecules)
            similarity = 0.0;
            for value in similarity_values:
                similarity = similarity + value
            average_similarity_dict["compound_" + str(i + 1)] = (similarity / len(input_rdkit_molecules))

    return average_similarity_dict


def get_score_list_per_gen(infolder: str) -> Dict[str, Union[float, str]]:
    """
    Get the docking scores for each generation.

    This function reads ranked .smi files from each generation folder and
    get the docking scores for each generation.

    Args:
        infolder (str): Path to the folder containing all generation folders.

    Returns:
        Dict[str, Union[float, str]]: Dictionary of lists of docking scores
        for each generation, with generation names as keys.
    """
    average_affinity_dict = {}
    for gen_folder in os.listdir(infolder):
        if os.path.isdir(os.path.join(infolder, gen_folder)):
            gen_folder_name = infolder + os.sep + gen_folder + os.sep
            ranked_file = glob.glob(f"{gen_folder_name}*_ranked.smi")

            for rank_file in ranked_file:
                gen_affinity_list = []
                with open(rank_file, "r") as f:
                    for line in f:
                        line = line.replace("\n", "")
                        parts = line.split(
                            "\t"
                        )  # split line into parts separated by 4-spaces

                        choice_list = [parts[i] for i in range(len(parts))]
                        gen_affinity_list.append(float(choice_list[2]))

                gen_num = os.path.basename(rank_file).split("_")[1]
                gen_name = f"generation_{gen_num}"
                average_affinity_dict[gen_name] = gen_affinity_list

    return average_affinity_dict


def get_average_score_per_gen(infolder: str) -> Dict[str, Union[float, str]]:
    """
    Calculate the average docking score for each generation.

    This function reads ranked .smi files from each generation folder and
    calculates the average docking score for each generation.

    Args:
        infolder (str): Path to the folder containing all generation folders.

    Returns:
        Dict[str, Union[float, str]]: Dictionary of average docking scores
        for each generation, with generation names as keys.
    """
    average_affinity_dict = {}
    for gen_folder in os.listdir(infolder):
        if os.path.isdir(os.path.join(infolder, gen_folder)):
            gen_folder_name = infolder + os.sep + gen_folder + os.sep
            ranked_file = glob.glob(f"{gen_folder_name}*_ranked.smi")

            for rank_file in ranked_file:
                # write as a tab delineated .smi file
                with open(rank_file, "r") as f:
                    gen_affinity_sum = 0.0
                    num_lines_counter = 0.0
                    for line in f:
                        line = line.replace("\n", "")
                        parts = line.split(
                            "\t"
                        )  # split line into parts separated by 4-spaces

                        choice_list = [parts[i] for i in range(len(parts))]
                        gen_affinity_sum = gen_affinity_sum + float(choice_list[2])
                        num_lines_counter = num_lines_counter + 1.0

                gen_affinity_average = gen_affinity_sum / num_lines_counter

                gen_num = os.path.basename(rank_file).split("_")[1]
                gen_name = f"generation_{gen_num}"
                average_affinity_dict[gen_name] = gen_affinity_average

    print_gens(average_affinity_dict)
    return average_affinity_dict


def get_average_top_score_per_gen(infolder: str, top_score_per_gen: int) -> Dict[str, Union[float, str]]:
    """
    This script will get the average docking score of the top N number of
    ligands ranked .smi file from each generation.

    Inputs:
    :param str infolder: the path of the folder which has all of the
        generation folders
    :param int top_score_per_gen: the number of ligands to determine the
        average score. ie) if top_score_per_gen=50 it will return the average of
        the top 50 scores.

    Returns:
    :returns: dict average_affinity_dict: dictionary of average affinity
        scores for top_score_per_gen number of ligands
    """

    average_affinity_dict = {}

    for gen_folder in os.listdir(infolder):
        if os.path.isdir(os.path.join(infolder, gen_folder)):
            gen_folder_name = infolder + os.sep + gen_folder + os.sep
            ranked_file = glob.glob(f"{gen_folder_name}*_ranked.smi")

            for rank_file in ranked_file:
                # Check number of lines
                num_lines = 0
                with open(rank_file, "r") as rf:
                    for _ in rf:
                        num_lines = num_lines + 1

                if num_lines >= top_score_per_gen:
                    # read as a tab delineated .smi file
                    with open(rank_file, "r") as f:
                        gen_affinity_sum = 0.0

                        for i, line in enumerate(f.readlines()):
                            if i >= top_score_per_gen:
                                break
                            line = line.replace("\n", "")
                            parts = line.split(
                                "\t"
                            )  # split line into parts separated by 4-spaces

                            choice_list = [parts[j] for j in range(len(parts))]
                            gen_affinity_sum = gen_affinity_sum + float(choice_list[2])

                        gen_affinity_average = gen_affinity_sum / top_score_per_gen

                        gen_num = os.path.basename(rank_file).split("_")[1]
                        gen_name = f"generation_{gen_num}"
                        average_affinity_dict[gen_name] = gen_affinity_average

                else:
                    gen_num = os.path.basename(rank_file).split("_")[1]
                    gen_name = f"generation_{gen_num}"
                    average_affinity_dict[gen_name] = "N/A"

    print_gens(average_affinity_dict)
    return average_affinity_dict


def print_gens(average_affinity_dict: Dict[str, Union[float, str]]) -> None:
    """
    This prints out the average scores for each generation

    Inputs:
    :param dict average_affinity_dict: dictionary of average affinity scores
        for top_score_per_gen number of ligands
    """

    print("generation_number              average affinity score")
    affinity_keys = list(average_affinity_dict.keys())
    affinity_keys.sort(key=lambda x: int(x.split("_")[1]))
    for gen in affinity_keys:
        print(gen, "                  ", average_affinity_dict[gen])


def make_graph(dictionary: Dict[str, Union[float, str]]) -> Tuple[Optional[List[int]], Optional[List[float]]]:
    """
    Because some generations may not have 50 ligands this basically checks to see if
    there are enough ligands and prepares lists to be plotted

    Inputs:
    :param dict dictionary: dictionary of average affinity scores for
        top_score_per_gen number of ligands
    Returns:
    :returns: list list_generations: list of ints for each generation to be plotted.
        if a generation lacks ligands to generate the average it will return "N/A"
    :returns: list list_of_scores: list of averages for each generation;
        if a generation lacks ligands to generate the average it will return "N/A"
    """
    list_generations = []
    list_of_gen_names = []
    list_of_scores = []
    # print(dictionary)

    for key, score in dictionary.items():
        # print(key)
        list_of_gen_names.append(key)

        list_of_scores.append(score)

        gen = key.replace("generation_", "")

        gen = int(gen)
        list_generations.append(gen)
        list_of_gen_names.append(key)

    for i in list_of_scores:
        if i == "N/A":
            return None, None

    return list_generations, list_of_scores


def run_score_plotter(
    params: Dict[str, Any],
    dict_of_averages: Dict[str, Dict[str, Union[float, str]]],
    outfile: str,
) -> None:
    """
    This plots the averages into a matplotlib figure. It will require you to
    answer questions about titles and labels

    Inputs:
    :param dict params: dict of user variables which will govern how the
        programs runs
    :param dict dict_of_averages: a dictionary of dictionaries containing the
        average of each generation for the top 50,20, 10, and 1 ligand(s) and the
        overall average for each generation.
    :param str outfile: Path for the output file for the plot
    """

    top_15 = dict_of_averages["top_15"]
    top_10 = dict_of_averages["top_10"]
    top_5 = dict_of_averages["top_5"]
    top_1 = dict_of_averages["top_1"]

    list_generations_15 = []
    list_of_scores_15 = []
    list_generations_10 = []
    list_of_scores_10 = []

    average_affinity_dict = dict_of_averages["average_affinity_dict"]
    list_generations_average, list_of_scores_average = make_graph(average_affinity_dict)

    print_top_15 = all(top_15[key] != "N/A" for key in top_15.keys())
    if print_top_15:
        list_generations_15, list_of_scores_15 = make_graph(top_15)

    print_top_10 = all(top_10[key] != "N/A" for key in top_10.keys())
    if print_top_10:
        list_generations_10, list_of_scores_10 = make_graph(top_10)

    list_generations_ten, list_of_scores_ten = make_graph(top_5)
    list_generations_one, list_of_scores_one = make_graph(top_1)

    plt.clf()
    ax = plt.subplot(111)

    ax.plot(
        list_generations_average, list_of_scores_average, color="b", label="Average"
    )

    if print_top_15:
        ax.plot(list_generations_15, list_of_scores_15, color="c", label="Top 15")

    if print_top_10:
        ax.plot(list_generations_10, list_of_scores_10, color="m", label="Top 10")

    ax.plot(list_generations_ten, list_of_scores_ten, color="g", label="Top 5")
    ax.plot(list_generations_one, list_of_scores_one, color="r", label="Top 1")

    if params["plot_reference_lines"] is not None:
        for ref_info in params["plot_reference_lines"]:
            ax.axhline(
                y=ref_info[1], color=ref_info[2], linestyle=":", label=ref_info[0]
            )

    ax.set_ylim()

    # Get Customizations
    receptor_name = os.path.basename(params["receptor_path"])
    title_of_figure = f"Scores for {receptor_name}"
    plt.title(title_of_figure, fontweight="semibold")

    # Put a legend to the right of the current axis
    ax.legend(loc="center left", bbox_to_anchor=(1, 0.274), fontsize="small")
    ax.set_ylim()

    scoring_type = params["vina_like_executable"]
    if "vina" in str(scoring_type):
        y_label = "Docking Affinity (kcal/mol)"
    else:
        y_label = "Fitness Score"
    plt.ylabel(y_label, fontweight="semibold")

    ax.xaxis.set_major_locator(MaxNLocator(integer=True))
    plt.xlabel("Generation Number", fontweight="semibold")

    plt.savefig(outfile, bbox_inches="tight", format=params["outfile_format"], dpi=1000)


def run_boxplot(
    params: Dict[str, Any],
    dictionary_of_values: Dict[str, Dict[str, Union[float, str]]],
    outfile: str,
    key_start_with: str,
    x_label: str,
    y_label: str,
    title_of_figure: str,
) -> None:
    data = []
    yticklabels = []
    for i in range(len(dictionary_of_values)):
        data.append(dictionary_of_values[key_start_with + "_" + str(i + 1)])
        yticklabels.append(key_start_with + "_" + str(i + 1))

    plt.clf()
    fig = plt.figure(figsize=(10, 7))
    ax = fig.add_subplot(111)

    # Creating plot with customizations
    bp = ax.boxplot(data, patch_artist=True, notch=False, vert=0,
                    showmeans=True,
                    meanprops={"markerfacecolor": "black", "markeredgecolor": "black"})
    for median in bp['medians']:
        median.set_color('black')

    # Setting x-axis labels

    plt.xlabel(x_label, fontweight="semibold")

    plt.ylabel(y_label, fontweight="semibold")
    ax.set_yticklabels(yticklabels)

    # Adding title
    title_of_figure = title_of_figure if title_of_figure is not None else ""
    plt.title(title_of_figure, fontweight="semibold")

    # Show plot
    plt.savefig(outfile, bbox_inches="tight", format=params["outfile_format"], dpi=1000)


def run_plotter(
    params: Dict[str, Any],
    dictionary_of_values: Dict[str, Dict[str, Union[float, str]]],
    outfile: str,
    key_start_with: str,
    x_label: str,
    y_label: str,
    title_of_figure: str,
) -> None:

    x = []
    y = []
    for i in range(len(dictionary_of_values)):
        y.append(dictionary_of_values[key_start_with + "_" + str(i + 1)])
        x.append(i + 1)

    # Create the plot
    plt.clf()
    plt.plot(x, y, marker='o', linestyle='-', color='b')

    # Add titles and labels
    plt.title(title_of_figure if title_of_figure is not None else "", fontweight="semibold")
    plt.xlabel(x_label if x_label is not None else "", fontweight="semibold")
    plt.ylabel(y_label if y_label is not None else "", fontweight="semibold")

    # Add a legend
    plt.legend()

    # Show plot
    plt.savefig(outfile, bbox_inches="tight", format=params["outfile_format"], dpi=1000)


def print_data_table(infolder: str) -> Dict[str, Any]:
    """
    This function takes a folder of an Autogrow Run and a list of all folders
    within the infolder, and finds the average of each generation, the average
    of the top 50,20, 10, and 1 ligand(s) in each generation.

    It prints the average docking score values in a table and returns that
    information as a dictionary of dictionaries.

    Inputs:
    :param str infolder: a string for the file path to a directory containing
        an Autogrow run.

    Returns
    :returns: dict dict_of_averages: a dictionary of dictionaries containing
        the average of each generation for the top 50,20, 10, and 1 ligand(s) and
        the overall average for each generation.
    """

    print("Overall Scoring Average for all Compounds")
    average_affinity_dict = get_average_score_per_gen(infolder)
    print("")
    print("Average for Top Scoring Compounds")
    print("Number of top scoring compounds: ", 15)
    top_15 = get_average_top_score_per_gen(infolder, 15)
    print("")
    print("Average for Top Scoring Compounds")
    print("Number of top scoring compounds: ", 10)
    top_10 = get_average_top_score_per_gen(infolder, 10)
    print("")
    print("Average for Top Scoring Compounds")
    print("Number of top scoring compounds: ", 5)
    top_5 = get_average_top_score_per_gen(infolder, 5)
    print("")
    print("Best Score per generation")
    print("Number of top scoring compounds: ", 1)
    top_1 = get_average_top_score_per_gen(infolder, 1)
    print("")
    print("")
    return {
        "average_affinity_dict": average_affinity_dict,
        "top_15": top_15,
        "top_10": top_10,
        "top_5": top_5,
        "top_1": top_1,
    }


def generate_figures(params: Dict[str, Any]) -> None:
    """
    This runs everything to make a line plot of the results of an Autogrow
    simulation.

    Inputs:
    :param dict params: dict of user variables which will govern how the
        programs runs
    """

    infolder = params["infolder"]
    outfile = params["outfile"]

    dict_of_averages = print_data_table(infolder)
    run_score_plotter(params, dict_of_averages,
                      outfile + os.sep + "score_plotter_by_generation." + params["outfile_format"])

    dict_of_score_lists = get_score_list_per_gen(infolder)
    scoring_type = params["vina_like_executable"]
    if "vina" in str(scoring_type):
        x_label = "Docking Affinity (kcal/mol)"
    else:
        x_label = "Fitness Score"
    receptor_name = os.path.basename(params["receptor_path"])
    run_boxplot(params, dict_of_score_lists,
                outfile + os.sep + "score_boxplot_by_generation." + params["outfile_format"],
                key_start_with="generation",
                x_label=x_label,
                y_label="Number of Generations",
                title_of_figure="Scores for " + receptor_name)

    source_file = str(params["source_compound_file"])
    dict_of_similarity_lists = get_similarity_list_per_input_comp(infolder, source_file)
    run_boxplot(params, dict_of_similarity_lists,
                outfile + os.sep + "similarity_boxplot_for_input_compounds." + params["outfile_format"],
                key_start_with="compound",
                x_label="Dice Similarity Values",
                y_label="Input Compounds",
                title_of_figure=None)

    dict_of_similarity_lists = get_ave_similarity_per_generated_comp(infolder, source_file)
    run_plotter(params, dict_of_similarity_lists,
                outfile + os.sep + "average_similarity_plotter_for_generated_compounds." + params["outfile_format"],
                key_start_with="compound",
                x_label="New compounds (ID) sorted from the highest to lowest affinity",
                y_label="Average similarity",
                title_of_figure=None)


def retrieve_vars_dict(autogrow_vars_json: str) -> Dict[str, Any]:
    """
    This will retrieve a variable dictionary from a AutoGrow vars json file.

    Inputs:
    :param str autogrow_vars_json: path to AutoGrow json variable file
    Returns:
    :returns: dict params: a dictionary of variable to use
    """
    if os.path.exists(autogrow_vars_json) is False:
        raise Exception(
            "variable file could not be found. It should be the \
            vars.json file written by AutoGrow in the output folder of the run."
        )
    try:
        with open(autogrow_vars_json, "r") as f:
            params = json.load(f)
    except Exception as e:
        raise Exception(
            "variable file would not import. It should be the \
            vars.json file written by AutoGrow in the output folder of the run."
        ) from e
    return params


def process_inputs(inputs: Dict[str, Any]) -> Dict[str, Any]:
    """
    This will handle processing all parameters.

    inputs:
    :params dict inputs: dictionary of argparse parameters
    Returns:
    :returns: dict vars_dict: dictionary of argparse parameters
    """

    # handle input information
    inputs["infolder"] = os.path.abspath(inputs["infolder"]) + os.sep
    if os.path.exists(inputs["infolder"]) is False:
        raise Exception(
            "Input folder {} does not\
            exist.".format(
                inputs["infolder"]
            )
        )

    # get vars dict from last run
    inputs["vars_json"] = inputs["infolder"] + "vars.json"
    if os.path.exists(inputs["vars_json"]) is False:
        raise Exception(
            "Input folder {} does not contain the vars.json file \
            necessary to run script. Please make sure the vars.json is in the \
            folder.".format(
                inputs["infolder"]
            )
        )

    try:
        with open(inputs["vars_json"], "r") as f:
            vars_dict = json.load(f)
    except Exception as e:
        raise Exception(
            "variable file would not import. It should be the \
            vars.json file written by AutoGrow in the output folder of the run."
        ) from e

    if "outfile_format" in inputs:
        if inputs["outfile_format"] is None:
            inputs["outfile_format"] = "svg"
        if inputs["outfile_format"].lower() not in ["svg", "png", "jpg", "pdf"]:
            raise Exception("outfile_format not a valid format")

    if "outfile" in inputs and inputs["outfile"] is not None:
        if os.path.dirname(inputs["outfile"]) is False:
            try:
                os.mkdir(os.path.dirname(inputs["outfile"]))
            except Exception as exc:
                raise Exception("outfile directory does not exist") from exc
        if os.path.dirname(inputs["outfile"]) is False:
            raise Exception("outfile directory does not exist")
    else:
        inputs["outfile"] = (
            inputs["infolder"] + os.sep + "data_line_plot." + inputs["outfile_format"]
        )

    # update --plot_reference_lines
    if "plot_reference_lines" not in inputs.keys():
        inputs["plot_reference_lines"] = None

    if inputs["plot_reference_lines"] is not None:
        _parse_plot_reference_lines(inputs)
    # overwrite and return vars_dict with input commands
    for key in inputs:
        vars_dict[key] = inputs[key]

    return vars_dict


def _parse_plot_reference_lines(inputs: Dict[str, Any]) -> None:
    # names of all matplotlib color options
    matplot_colors = matplotlib.colors.get_named_colors_mapping().keys()

    ref_lines = inputs["plot_reference_lines"].replace("[[", "[").replace("]]", "]")
    ref_lines = ref_lines.split("],")
    ref_lines = [ref.replace("]", "").replace("[", "").split(",") for ref in ref_lines]

    new_ref_lines = []
    failed_io = False
    for ref_info in ref_lines:
        if len(ref_info) != 3:
            failed_io = True
            break

        # make new list with 1st item the str name
        temp_ref_lines: List[Union[str, float]] = [str(ref_info[0])]

        try:
            temp_ref_lines.append(float(ref_info[1]))
        except Exception:
            failed_io = True
            break
        if str(ref_info[2]) not in matplot_colors:
            print(f"COULD NOT FIND COLOR: {str(ref_info[2])}")
            failed_io = True
            break
        temp_ref_lines.append(str(ref_info[2]))
        new_ref_lines.append(temp_ref_lines)

    if failed_io is True:
        printout = (
            "\n --plot_reference_lines must be list of lists where each "
            + "sublist has three pieces of information in this "
        )
        printout += "order:\n\t [name, value, matplotlib_color]\n"
        printout += "more details can be found using the -h option\n"
        print(printout)
        raise Exception(printout)
    inputs["plot_reference_lines"] = new_ref_lines


def main():
    PARSER = argparse.ArgumentParser()

    # Get needed info
    PARSER.add_argument(
        "--outfile",
        "-o",
        metavar="param.outfile",
        required=False,
        default=None,
        help="Path to folder to output files. It will be created if does not exist. \
        If not provide it will be placed in the infolder/data_line_plot.svg",
    )
    PARSER.add_argument(
        "--outfile_format",
        metavar="param.outfile_format",
        type=str,
        default="svg",
        choices=["svg", "png", "jpg", "pdf"],
        help="The type of file for figure to be exported as default is .svg file.",
    )
    PARSER.add_argument(
        "--infolder",
        "-i",
        metavar="param.infolder",
        required=True,
        help="Path to input folder containing the AutoGrow run. This should be the \
            top folder which contains the vars.json file.",
    )
    PARSER.add_argument(
        "--plot_reference_lines",
        default=None,
        help="This will be a list of lists, with each sublist being a different \
            dotted-line reference to plot. For each sublist the order of \
            information should be: [name, value, matplotlib_color] \
            For example a [['Olaparib score',-12.8,'y'],['Niraparib score',-10.7,'k']] \
            will add horizontal dotted lines at -12.8 (yellow) and -10.7 (black) \
            with Olaparib and Niraparib added to the legend. \
            Spaces must be within quotes and not be between variables. \
            matplotlib colors can be found with mcolors.get_named_colors_mapping().keys()",
    )

    ARGSDICT = vars(PARSER.parse_args())

    # copying ARGSDICT so we can delete out of while iterating through the
    # original ARGSDICT
    INPUTS = copy.deepcopy(ARGSDICT)

    for k, v in ARGSDICT.items():
        if v is None:
            del INPUTS[k]

    USER_VARS = process_inputs(INPUTS)

    generate_figures(USER_VARS)

    print(f'FINISHED {USER_VARS["outfile"]}')

    print("finished")


if __name__ == "__main__":
    main()
